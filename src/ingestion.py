import os
from sec_edgar_downloader import Downloader
from langchain_community.document_loaders import BSHTMLLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import shutil

# --- é…ç½®éƒ¨åˆ† ---
DATA_DIR = "data"
SEC_DIR = os.path.join(DATA_DIR, "sec_filings")
DB_DIR = os.path.join(DATA_DIR, "vector_db")

# SEC è¦æ±‚ä¸‹è½½æ—¶æä¾› User-Agent (æ ¼å¼: "Name email@domain.com")
# è¯·åŠ¡å¿…ä¿®æ”¹è¿™é‡Œï¼Œæˆ–è€…åœ¨ .env ä¸­è®¾ç½® SEC_EMAIL
USER_EMAIL = os.getenv("SEC_EMAIL", "student@university.edu") 
USER_NAME = "FinanceAgentProject"

def download_reports(tickers):
    """
    ä» SEC EDGAR ä¸‹è½½ 10-K (å¹´æŠ¥) å’Œ 10-Q (å­£æŠ¥)
    """
    print(f"ğŸš€ åˆå§‹åŒ–ä¸‹è½½å™¨... (User: {USER_NAME} <{USER_EMAIL}>)")
    dl = Downloader(USER_NAME, USER_EMAIL, SEC_DIR)
    
    for ticker in tickers:
        print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ {ticker} çš„è´¢æŠ¥...")
        # é™åˆ¶æ•°é‡ä»¥åŠ å¿«æ¼”ç¤ºé€Ÿåº¦ (1ä»½å¹´æŠ¥ï¼Œ1ä»½å­£æŠ¥)
        # å®é™…é¡¹ç›®ä¸­å¯ä»¥å°† limit è®¾ä¸º 5 æˆ–æ›´å¤š
        dl.get("10-K", ticker, limit=1)
        dl.get("10-Q", ticker, limit=1)
    
    print("âœ… æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆï¼")

def ingest_data():
    """
    è¯»å– HTML -> æ¸…æ´— -> åˆ‡å— -> å‘é‡åŒ– -> å­˜å…¥ ChromaDB
    """
    # 1. åŠ è½½æ•°æ®
    print("ğŸ“‚ å¼€å§‹åŠ è½½ HTML æ–‡ä»¶...")
    # SEC ä¸‹è½½çš„æ˜¯ HTML æ ¼å¼ï¼Œæˆ‘ä»¬ç”¨ BSHTMLLoader æå–çº¯æ–‡æœ¬
    loader = DirectoryLoader(
        SEC_DIR,
        glob="**/*.html",
        loader_cls=BSHTMLLoader,
        show_progress=True,
        use_multithreading=True
    )
    docs = loader.load()
    print(f"ğŸ“„ åŠ è½½äº† {len(docs)} ä¸ªæ–‡æ¡£")

    if len(docs) == 0:
        print("âš ï¸ æœªæ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·å…ˆè¿è¡Œä¸‹è½½æ­¥éª¤ï¼")
        return

    # 2. æ–‡æœ¬åˆ‡å— (Chunking)
    print("âœ‚ï¸ æ­£åœ¨åˆ‡åˆ†æ–‡æœ¬...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,       # æ¯ä¸ªå—çº¦ 1000 å­—ç¬¦
        chunk_overlap=100,     # é‡å  100 å­—ç¬¦ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡ä¸¢å¤±
        separators=["\n\n", "\n", " ", ""]
    )
    splits = text_splitter.split_documents(docs)
    print(f"ğŸ§© ç”Ÿæˆäº† {len(splits)} ä¸ªæ–‡æœ¬å— (Chunks)")

    # 3. å‘é‡åŒ–ä¸å­˜å‚¨ (Embedding & Storage)
    print("ğŸ’¾ æ­£åœ¨ç”Ÿæˆå‘é‡å¹¶å­˜å…¥ ChromaDB (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    
    # ä½¿ç”¨ BGE-Small æ¨¡å‹ï¼Œæ•ˆæœå¥½ä¸”é€Ÿåº¦å¿«
    embedding_model = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-en-v1.5",
        model_kwargs={'device': 'cpu'}, # å¦‚æœæœ‰ GPU æ”¹ä¸º 'cuda'
        encode_kwargs={'normalize_embeddings': True}
    )
    
    # åˆ›å»ºå¹¶æŒä¹…åŒ–å‘é‡åº“
    if os.path.exists(DB_DIR):
        print("   (æ£€æµ‹åˆ°å·²æœ‰æ•°æ®åº“ï¼Œæ­£åœ¨è¿½åŠ æ•°æ®...)")
    
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_model,
        persist_directory=DB_DIR
    )
    print(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºæˆåŠŸï¼å­˜å‚¨ä½ç½®: {DB_DIR}")

if __name__ == "__main__":
    # ç›®æ ‡å…¬å¸ï¼šApple, Microsoft, Tesla
    target_tickers = ["AAPL", "MSFT", "TSLA"]
    
    # --- æ­¥éª¤å¼€å…³ ---
    # ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ï¼Œè¯·ç¡®ä¿ download=True
    # ä¹‹åå¦‚æœåªæƒ³é‡æ–°ç”Ÿæˆæ•°æ®åº“ï¼Œå¯ä»¥è®¾ä¸º False
    RUN_DOWNLOAD = True
    
    if RUN_DOWNLOAD:
        download_reports(target_tickers)
    
    ingest_data()